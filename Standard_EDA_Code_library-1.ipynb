{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA CLEANING\n",
    "\n",
    "# Import Libaries\n",
    "import pandas as pd\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas_profiling\n",
    "!pip install -q --upgrade pandas_profiling\n",
    "!pip install -q --upgrade yellowbrick\n",
    "import numpy as np\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import pandas as pd                                                 # Importing for panel data analysis\n",
    "pd.set_option('display.max_columns', None)                          # Unfolding hidden features if the cardinality is high\n",
    "pd.set_option('display.max_colwidth', None)                         # Unfolding the max feature width for better clearity\n",
    "pd.set_option('display.max_rows', None)                             # Unfolding hidden data points if the cardinality is high\n",
    "pd.set_option('mode.chained_assignment', None)                      # Removing restriction over chained assignments operations\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)         # To suppress scientific notation over exponential values\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "from collections import Counter                                     # For counting hashable objects\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt                                     # Importing pyplot interface using matplotlib\n",
    "import plotly.graph_objs as go                                      # For Plotly interfaced graphs\n",
    "import seaborn as sns                                               # Importin seaborm library for interactive visualization\n",
    "%matplotlib inline\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings                                                     # Importing warning to disable runtime warnings\n",
    "warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once\n",
    "\n",
    "\n",
    "\n",
    "# Fetch CSV/Excel\n",
    "data = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/insaid2018/Term-1/master/Data/Casestudy/survey.csv')\n",
    "print('Data Shape:', data.shape)\n",
    "data.head()\n",
    "\n",
    "\n",
    "# Understanding dataset\n",
    "    data.info()\n",
    "    data.describe()                By default, this methor describes continuous variables  \n",
    "    data.describe(include = 'all') To be used to get unique values of categorical variables\n",
    "    data['Column Name'].nunique()        # Count of Unique Values in each Column\n",
    "    data['Column Name'].value_counts()   # Count of EACH UNIQUE value in a column\n",
    "    data['Column Name'].unique()\n",
    "    data['Column Name'].value_counts().keys()[0]  # Which item in a column has maximum frequency\n",
    "    \n",
    "    \n",
    "# MERGING OF TWO TABLES\n",
    "\n",
    "# GROUPBY OF TWO TABLES\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# HANDLING DUPLICATE RECORDS\n",
    "\n",
    "    # Check if duplicates exist\n",
    "    data.duplicated().any()\n",
    "    \n",
    "    # count duplicates\n",
    "    data.duplicated().sum()\n",
    "\n",
    "    # drop duplicates\n",
    "    data.drop_duplicates(inplace = True)\n",
    "    \n",
    "# DROP COLUMNS\n",
    "    data.drop(labels=['Postcode', 'Phone_Number', 'Timezone'], axis=1, inplace=True)\n",
    "    \n",
    "# DROP ROWS\n",
    "    data.drop(row index, axis=1, inplace=True)          # without square bracket\n",
    "    \n",
    "# HANDLING NULL VALUES\n",
    "\n",
    "    # Identify columns having null values\n",
    "    data.info()\n",
    "    data.isnull().sum()\n",
    "    data.shape[0]-data['Column Name'].count()\n",
    "\n",
    "    # Extract list of Columns and its corresponding missing values\n",
    "    null_frame = pd.DataFrame(index = data.columns.values)    #Extracting the series of all Column names\n",
    "    null_frame['Null Frequency'] = data.isnull().sum().values\n",
    "    \n",
    "    # Replace with value (median, mean, mode, 'custom string')\n",
    "    data['Column Name'].fillna(Value to be replaced WITH, inplace = True)\n",
    "    data['Column Name'].fillna(data['Column Name'].mode()[0], inplace = True)\n",
    "    data['Column Name'].fillna(data['Column Name'].median(), inplace = True)\n",
    "    data['Column Name'].fillna(data['Column Name'].mean(), inplace = True)\n",
    "    data['Column Name'] = data['Column Name'].replace(np.nan, data['Column Name'].mode()[0])\n",
    "\n",
    "\n",
    "    # Handling Null values in 'n' number of columns using for loop when SAME value to be placed)\n",
    "    For i in ['Col 1', 'Col 2',.... 'Col n']:\n",
    "       data[i].fillna()\n",
    "    \n",
    "# DROPPING NON-REQUIRED COLUMS\n",
    "    data.drop(['Column Name1','Column Name2'], axis=1, inplace=True)\n",
    "    \n",
    "# REPLACE SPECIFIC VALUES\n",
    "    data['Column Name'].replace(Value to be replaced, Value to be replaced WITH)\n",
    "    \n",
    "# Reviewing SAMPLE Values in a COLUMN\n",
    "    data.sample(30)  (number of sample values)\n",
    "    \n",
    "# Typecasting entire column with a particular data type\n",
    "    data['Column'].astype('O')\n",
    "        \n",
    "# Typecasting entire column with DATESTAMP data type    \n",
    "    data['Timestamp']= pd.to_datetime(data['Timestamp'])\n",
    "    \n",
    "# FILTER ROWS with specific logic \n",
    "    newdata = data[data['Age']<18]\n",
    "\n",
    "# IDENTIFY OUTLIERS\n",
    "    # For each Caontinuous Variables, identify a logical range and then replace outliers with MEAN or MEDIAN appropriately\n",
    "        \n",
    "    # REMOVE outlier records\n",
    "        newdata = data[data['Age']<75 | data['Age']>15]    \n",
    "        \n",
    "    # REPLACE outlier records\n",
    "        data['Age'][data['Age'] > 75] = data['Age'].median()\n",
    "        data['Age'][data['Age'] < 15] = data['Age'].median()    \n",
    "    \n",
    "# ADD NEW CUSTOM COLUMNS TO THE DATA FOR MORE ANALYSIS\n",
    "    NewColumn = data.LOGIC         #Add the logic as if the Column already exist in the dataset\n",
    "    \n",
    "# GROUP BY\n",
    "    data.groupby(['family_history','treatment'])['family_history'].count()\n",
    "    \n",
    "# Hygiene of Categorical Columns\n",
    "    unique_gender = data['Gender'].str.lower().unique()\n",
    "    \n",
    "    # Stratas of Gender category\n",
    "        M = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \n",
    "            \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \n",
    "            \"cis male\"]\n",
    "        T = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \n",
    "             \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \n",
    "             \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \n",
    "             \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \n",
    "             \"ostensibly male, unsure what that really means\"]           \n",
    "        F = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \", \n",
    "              \"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "    # Iterate over rows and replace the inconsistent data with right data\n",
    "        data['Gender'] = data['Gender'].replace(M, 'M').replace(F, 'F').replace(T, 'T')\n",
    "\n",
    "    # Remove rest of the unnecessary text\n",
    "        stk_list = ['A little about you', 'p']\n",
    "        data = data[~data['Gender'].isin(stk_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c97e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA \n",
    "\n",
    "ASK QUESTIONS....  REMEMBER the RULE .....   RRnV\n",
    "\n",
    "Rules for ASKING QUESIONS..\n",
    "\n",
    "1.  Relevant    (Is it in context of the problem statement ?)\n",
    "2.  Reasonable  (Do we have related data to answer ?)\n",
    "3.  nonVage     (Is the question Vague ?)\n",
    "\n",
    "STRATEGY\n",
    "\n",
    "1. UniVariate Analysis\n",
    "2. BiVariate Analysis\n",
    "3. MultiVariate Analysis\n",
    "\n",
    "GUIDANCE\n",
    "\n",
    "1. Maximum 15 +- 5 Questions\n",
    "\n",
    "\n",
    "\n",
    "# TOP 3 based on COUNT\n",
    "    list(data['Country'].value_counts()[:3].index)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
